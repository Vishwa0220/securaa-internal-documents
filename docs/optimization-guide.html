<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Performance Optimization Guide - Securaa Platform Documentation</title>
    <link rel="stylesheet" href="assets/css/documentation.css">
</head>
<body>
    <header class="main-header">
        <h1>Securaa Platform Documentation</h1>
        <p>Comprehensive documentation for Securaa security platform services</p>
    </header>
    
    
        <nav class="documentation-nav">
            <ul>
                <li><a href="index.html">Home</a></li>
                <li><a href="securaa-ris-high-level-design.html">RIS High Level Design</a></li>
                <li><a href="securaa-ris-low-level-design.html">RIS Low Level Design</a></li>
                <li><a href="securaa-ris-client-documentation.html">RIS Client Documentation</a></li>
                <li><a href="securaa-ris-server-documentation.html">RIS Server Documentation</a></li>
                <li><a href="securaa-playbook-high-level-design.html">Securaa Playbook High Level Design</a></li>
                <li><a href="securaa-playbook-low-level-design.html">Securaa Playbook Low Level Design</a></li>
                <li><a href="optimization-guide.html" class="active">Optimization Guide</a></li>
                <li><a href="securaa-siem-high-level-design.html">Securaa SIEM High Level Design</a></li>
                <li><a href="securaa-siem-low-level-design.html">Securaa SIEM Low Level Design</a></li>
                <li><a href="securaa-platform-high-level-design.html">Securaa Platform</a></li>
                <li><a href="process-manager-high-level-design.html">Process Manager High Level Design</a></li>
                <li><a href="process-manager-low-level-design.html">Process Manager Low Level Design</a></li>
                <li><a href="securaa-user-high-level-design.html">Securaa User High Level Design</a></li>
                <li><a href="securaa-user-low-level-design.html">Securaa User Low Level Design</a></li>
                <li><a href="securaa-custom-services-high-level-design.html">Securaa Custom Services High Level Design</a></li>
                <li><a href="securaa-custom-services-low-level-design.html">Securaa Custom Services Low Level Design</a></li>
                <li><a href="securaa-custom-utils-high-level-design.html">Securaa Custom Utils High Level Design</a></li>
                <li><a href="securaa-custom-utils-low-level-design.html">Securaa Custom Utils Low Level Design</a></li>
                <li><a href="securaa-make-system-high-level-design.html">Securaa Make System High Level Design</a></li>
                <li><a href="securaa-make-system-low-level-design.html">Securaa Make System Low Level Design</a></li>
            </ul>
        </nav>
        
    
    <main class="main-content">
        <h1>Securaa Playbook Service - Performance Optimization Guide</h1>
<h2>Document Information</h2>
<ul>
<li><strong>Service</strong>: Securaa Playbook Service</li>
<li><strong>Target Audience</strong>: Development Team</li>
<li><strong>Priority</strong>: High Impact Performance Improvements</li>
<li><strong>Date</strong>: September 11, 2025</li>
<li><strong>Estimated Implementation Time</strong>: 4-6 weeks</li>
</ul>
<p>---</p>
<h2>üéØ <strong>Executive Summary</strong></h2>
<p>This document provides specific, actionable optimization strategies for the Securaa Playbook Service that can deliver:</p>
<ul>
<li><strong>5-10x query performance improvement</strong></li>
<li><strong>3-4x concurrent request handling</strong></li>
<li><strong>50-70% reduction in memory usage</strong></li>
<li><strong>2-3x task execution throughput</strong></li>
</ul>
<p>---</p>
<h2>üìã <strong>Priority 1: Database Optimizations (Week 1-2)</strong></h2>
<h3><strong>1.1 Critical Index Creation</strong></h3>
<strong>Impact</strong>: 5-10x query performance improvement  
<strong>Effort</strong>: 1 day  
<strong>Files to modify</strong>: Database migration scripts
<pre><code class="language-javascript">// Add these indexes immediately - HIGH IMPACT
<p>db.playbook_execution_collection.createIndex({</p>
<p>    "tenant_code": 1, </p>
<p>    "execution_status": 1, </p>
<p>    "createddate": -1</p>
<p>});</p>
<p>db.playbook_execution_collection.createIndex({</p>
<p>    "uid": 1, </p>
<p>    "createddate": -1</p>
<p>});</p>
<p>db.task_execution_collection.createIndex({</p>
<p>    "peid": 1, </p>
<p>    "task_seq": 1</p>
<p>});</p>
<p>db.task_execution_collection.createIndex({</p>
<p>    "tenant_code": 1, </p>
<p>    "alert_id": 1, </p>
<p>    "status": 1</p>
<p>});</p>
<p>db.playbook_collection.createIndex({</p>
<p>    "tenant_code": 1, </p>
<p>    "status": 1, </p>
<p>    "category_id": 1</p>
<p>});</p>
<p>// Compound index for top playbooks query</p>
<p>db.playbook_execution_collection.createIndex({</p>
<p>    "execution_status": 1,</p>
<p>    "createddate": -1,</p>
<p>    "pid": 1,</p>
<p>    "playbook_runtime": 1</p>
<p>});</code></pre></p>
<h3><strong>1.2 Query Optimization in averagePlaybookRunTime.go</strong></h3>
<strong>Current Issue</strong>: Inefficient aggregation pipeline  
<strong>File</strong>: <code>services/averagePlaybookRunTime.go</code>
<pre><code class="language-go">// BEFORE (Current implementation around line 93):
<p>topPlaybookAvrPipeline := bson.A{</p>
<p>    bson.D{{"$match", matchQuery}},</p>
<p>    bson.D{{"$sort", bson.D{{"createddate", -1}}}},</p>
<p>    bson.D{{"$group", bson.M{"_id": "$pid",</p>
<p>        "name":    bson.M{"$first": "$playbook_name"},</p>
<p>        "average": bson.M{"$avg": "$playbook_runtime"}}}},</p>
<p>    bson.D{{"$sort", bson.D{{"average", -1}}}},</p>
<p>    bson.D{{"$limit", 5}},</p>
<p>}</p>
<p>// AFTER (Optimized version):</p>
<p>topPlaybookAvrPipeline := bson.A{</p>
<p>    bson.D{{"$match", matchQuery}},</p>
<p>    // Use $group first to reduce data volume</p>
<p>    bson.D{{"$group", bson.M{</p>
<p>        "_id": "$pid",</p>
<p>        "name": bson.M{"$first": "$playbook_name"},</p>
<p>        "average": bson.M{"$avg": "$playbook_runtime"},</p>
<p>        "count": bson.M{"$sum": 1}}}},</p>
<p>    // Sort after grouping (smaller dataset)</p>
<p>    bson.D{{"$sort", bson.D{{"average", -1}}}},</p>
<p>    bson.D{{"$limit", 5}},</p>
<p>    // Add projection to reduce network transfer</p>
<p>    bson.D{{"$project", bson.M{</p>
<p>        "name": 1,</p>
<p>        "average": 1,</p>
<p>        "count": 1}}},</p>
<p>}</code></pre></p>
<h3><strong>1.3 Batch Operations Implementation</strong></h3>
<strong>File</strong>: Create new <code>services/batchOperationService.go</code>
<pre><code class="language-go">package services
<p>import (</p>
<p>    "context"</p>
<p>    "go.mongodb.org/mongo-driver/bson"</p>
<p>    "go.mongodb.org/mongo-driver/mongo"</p>
<p>    "go.mongodb.org/mongo-driver/mongo/options"</p>
<p>    "time"</p>
<p>)</p>
<p>type BatchOperationService struct {</p>
<p>    collection <em>mongo.Collection</p>
<p>}</p>
<p>type TaskStatusUpdate struct {</p>
<p>    TaskRequestID string</p>
<p>    Status        string</p>
<p>    Response      string</p>
<p>    UpdatedDate   int64</p>
<p>}</p>
<p>func NewBatchOperationService(collection </em>mongo.Collection) <em>BatchOperationService {</p>
<p>    return &BatchOperationService{collection: collection}</p>
<p>}</p>
<p>func (service </em>BatchOperationService) BatchUpdateTaskStatus(</p>
<p>    updates []TaskStatusUpdate,</p>
<p>) error {</p>
<p>    const batchSize = 1000</p>
    
<p>    for i := 0; i < len(updates); i += batchSize {</p>
<p>        end := i + batchSize</p>
<p>        if end > len(updates) {</p>
<p>            end = len(updates)</p>
<p>        }</p>
        
<p>        batch := updates[i:end]</p>
<p>        if err := service.processBatch(batch); err != nil {</p>
<p>            return err</p>
<p>        }</p>
<p>    }</p>
    
<p>    return nil</p>
<p>}</p>
<p>func (service <em>BatchOperationService) processBatch(batch []TaskStatusUpdate) error {</p>
<p>    var operations []mongo.WriteModel</p>
    
<p>    for _, update := range batch {</p>
<p>        filter := bson.M{"task_request_id": update.TaskRequestID}</p>
<p>        updateDoc := bson.M{</p>
<p>            "$set": bson.M{</p>
<p>                "status":       update.Status,</p>
<p>                "response":     update.Response,</p>
<p>                "updated_date": update.UpdatedDate,</p>
<p>            },</p>
<p>        }</p>
        
<p>        operation := mongo.NewUpdateOneModel().</p>
<p>            SetFilter(filter).</p>
<p>            SetUpdate(updateDoc)</p>
        
<p>        operations = append(operations, operation)</p>
<p>    }</p>
    
<p>    // Execute bulk write with unordered operations for better performance</p>
<p>    opts := options.BulkWrite().SetOrdered(false)</p>
<p>    _, err := service.collection.BulkWrite(</p>
<p>        context.Background(),</p>
<p>        operations,</p>
<p>        opts,</p>
<p>    )</p>
    
<p>    return err</p>
<p>}</p>
<p>// Usage in controllers:</p>
<p>func (controller </em>TaskController) UpdateMultipleTaskStatus(updates []TaskStatusUpdate) error {</p>
<p>    batchService := NewBatchOperationService(controller.taskCollection)</p>
<p>    return batchService.BatchUpdateTaskStatus(updates)</p>
<p>}</code></pre></p>
<p>---</p>
<h2>üìã <strong>Priority 2: Connection Pool Optimization (Week 1)</strong></h2>
<h3><strong>2.1 MongoDB Connection Pool Configuration</strong></h3>
<strong>File</strong>: <code>app.go</code> - Modify <code>InitMongoSession</code> function
<pre><code class="language-go">// BEFORE (Current implementation):
<p>func (a <em>App) InitMongoSession(configObject config.ConfigStruct) {</p>
<p>    // Basic connection without optimization</p>
<p>}</p>
<p>// AFTER (Optimized version):</p>
<p>func (a </em>App) InitMongoSession(configObject config.ConfigStruct) {</p>
<p>    // Optimized MongoDB connection configuration</p>
<p>    clientOptions := options.Client().</p>
<p>        ApplyURI(configObject.DatabaseConfig.MongoURI).</p>
<p>        SetMaxPoolSize(100).                    // Increase max connections</p>
<p>        SetMinPoolSize(10).                     // Maintain minimum connections</p>
<p>        SetMaxConnIdleTime(30 <em> time.Minute).  // Keep connections alive longer</p>
<p>        SetConnectTimeout(10 </em> time.Second).   // Connection timeout</p>
<p>        SetSocketTimeout(30 <em> time.Second).    // Socket timeout</p>
<p>        SetServerSelectionTimeout(5 </em> time.Second). // Server selection timeout</p>
<p>        SetHeartbeatInterval(10 <em> time.Second). // Health check interval</p>
<p>        SetRetryWrites(true).                   // Enable retry writes</p>
<p>        SetRetryReads(true)                     // Enable retry reads</p>
<p>    client, err := mongo.Connect(context.Background(), clientOptions)</p>
<p>    if err != nil {</p>
<p>        logger.Fatal("Failed to connect to MongoDB", err)</p>
<p>    }</p>
<p>    // Test the connection</p>
<p>    err = client.Ping(context.Background(), nil)</p>
<p>    if err != nil {</p>
<p>        logger.Fatal("Failed to ping MongoDB", err)</p>
<p>    }</p>
<p>    // Store optimized client</p>
<p>    a.MongoClient = client</p>
<p>    logger.Info("MongoDB connection pool initialized with optimized settings")</p>
<p>}</code></pre></p>
<h3><strong>2.2 Redis Connection Pool Optimization</strong></h3>
<strong>File</strong>: Create new <code>cache/optimizedRedisClient.go</code>
<pre><code class="language-go">package cache
<p>import (</p>
<p>    "time"</p>
<p>    "github.com/go-redis/redis/v8"</p>
<p>)</p>
<p>type OptimizedRedisConfig struct {</p>
<p>    Host         string</p>
<p>    Port         int</p>
<p>    Password     string</p>
<p>    Database     int</p>
<p>    PoolSize     int</p>
<p>    MinIdleConns int</p>
<p>    IdleTimeout  time.Duration</p>
<p>    MaxRetries   int</p>
<p>}</p>
<p>func NewOptimizedRedisClient(config OptimizedRedisConfig) </em>redis.Client {</p>
<p>    return redis.NewClient(&redis.Options{</p>
<p>        Addr:         fmt.Sprintf("%s:%d", config.Host, config.Port),</p>
<p>        Password:     config.Password,</p>
<p>        DB:           config.Database,</p>
<p>        PoolSize:     config.PoolSize,      // Default: 30, Recommended: 50-100</p>
<p>        MinIdleConns: config.MinIdleConns,  // Default: 0, Recommended: 10-20</p>
<p>        IdleTimeout:  config.IdleTimeout,   // Default: 5min, Recommended: 10-30min</p>
<p>        MaxRetries:   config.MaxRetries,    // Default: 3, Recommended: 5</p>
<p>        DialTimeout:  5 <em> time.Second,</p>
<p>        ReadTimeout:  10 </em> time.Second,</p>
<p>        WriteTimeout: 10 <em> time.Second,</p>
<p>        PoolTimeout:  15 </em> time.Second,</p>
<p>    })</p>
<p>}</p>
<p>// Usage in cacheControllers/cacheController.go:</p>
<p>func init() {</p>
<p>    config := OptimizedRedisConfig{</p>
<p>        Host:         os.Getenv("REDIS_HOST"),</p>
<p>        Port:         6379,</p>
<p>        PoolSize:     80,</p>
<p>        MinIdleConns: 15,</p>
<p>        IdleTimeout:  20 <em> time.Minute,</p>
<p>        MaxRetries:   5,</p>
<p>    }</p>
    
<p>    redisClient = NewOptimizedRedisClient(config)</p>
<p>}</code></pre></p>
<h3><strong>2.3 HTTP Client Pool Configuration</strong></h3>
<strong>File</strong>: Create new <code>utils/httpClientPool.go</code>
<pre><code class="language-go">package utils
<p>import (</p>
<p>    "net/http"</p>
<p>    "time"</p>
<p>)</p>
<p>var (</p>
<p>    optimizedHTTPClient </em>http.Client</p>
<p>    once                sync.Once</p>
<p>)</p>
<p>func GetOptimizedHTTPClient() <em>http.Client {</p>
<p>    once.Do(func() {</p>
<p>        transport := &http.Transport{</p>
<p>            MaxIdleConns:        100,               // Total idle connections</p>
<p>            MaxIdleConnsPerHost: 20,                // Idle connections per host</p>
<p>            MaxConnsPerHost:     50,                // Max connections per host</p>
<p>            IdleConnTimeout:     90 </em> time.Second,  // Keep connections alive</p>
<p>            TLSHandshakeTimeout: 10 <em> time.Second,  // TLS handshake timeout</p>
<p>            DisableKeepAlives:   false,             // Enable keep-alive</p>
<p>            ForceAttemptHTTP2:   true,              // Use HTTP/2 when possible</p>
<p>        }</p>
<p>        optimizedHTTPClient = &http.Client{</p>
<p>            Transport: transport,</p>
<p>            Timeout:   30 </em> time.Second, // Overall request timeout</p>
<p>        }</p>
<p>    })</p>
    
<p>    return optimizedHTTPClient</p>
<p>}</p>
<p>// Usage in integration calls:</p>
<p>func MakeAPICall(url string, data []byte) (<em>http.Response, error) {</p>
<p>    client := GetOptimizedHTTPClient()</p>
<p>    req, err := http.NewRequest("POST", url, bytes.NewBuffer(data))</p>
<p>    if err != nil {</p>
<p>        return nil, err</p>
<p>    }</p>
    
<p>    return client.Do(req)</p>
<p>}</code></pre></p>
<p>---</p>
<h2>üìã <strong>Priority 3: Parallel Processing Implementation (Week 2-3)</strong></h2>
<h3><strong>3.1 Worker Pool for Task Execution</strong></h3>
<strong>File</strong>: Create new <code>executionControllers/workerPool.go</code>
<pre><code class="language-go">package executionControllers
<p>import (</p>
<p>    "context"</p>
<p>    "sync"</p>
<p>    "securaa_services/securaa_playbook/executionModels"</p>
<p>)</p>
<p>type TaskWorkerPool struct {</p>
<p>    taskQueue   chan executionModels.PlayBookTask</p>
<p>    resultQueue chan TaskResult</p>
<p>    errorQueue  chan error</p>
<p>    stopSignal  chan struct{}</p>
<p>    workers     int</p>
<p>    wg          sync.WaitGroup</p>
<p>    controller  </em>PlaybookExecutionController</p>
<p>}</p>
<p>type TaskResult struct {</p>
<p>    TaskSeq  int</p>
<p>    Success  bool</p>
<p>    Response string</p>
<p>    Error    error</p>
<p>    Duration time.Duration</p>
<p>}</p>
<p>func NewTaskWorkerPool(workers int, bufferSize int, controller <em>PlaybookExecutionController) </em>TaskWorkerPool {</p>
<p>    return &TaskWorkerPool{</p>
<p>        taskQueue:   make(chan executionModels.PlayBookTask, bufferSize),</p>
<p>        resultQueue: make(chan TaskResult, bufferSize),</p>
<p>        errorQueue:  make(chan error, bufferSize),</p>
<p>        stopSignal:  make(chan struct{}),</p>
<p>        workers:     workers,</p>
<p>        controller:  controller,</p>
<p>    }</p>
<p>}</p>
<p>func (pool <em>TaskWorkerPool) Start() {</p>
<p>    for i := 0; i < pool.workers; i++ {</p>
<p>        pool.wg.Add(1)</p>
<p>        go pool.worker(i)</p>
<p>    }</p>
<p>}</p>
<p>func (pool </em>TaskWorkerPool) worker(workerID int) {</p>
<p>    defer pool.wg.Done()</p>
    
<p>    for {</p>
<p>        select {</p>
<p>        case task := <-pool.taskQueue:</p>
<p>            result := pool.processTask(task, workerID)</p>
<p>            pool.resultQueue <- result</p>
            
<p>        case <-pool.stopSignal:</p>
<p>            logger.Info("Worker stopping", "worker_id", workerID)</p>
<p>            return</p>
<p>        }</p>
<p>    }</p>
<p>}</p>
<p>func (pool <em>TaskWorkerPool) processTask(task executionModels.PlayBookTask, workerID int) TaskResult {</p>
<p>    startTime := time.Now()</p>
    
<p>    defer func() {</p>
<p>        if r := recover(); r != nil {</p>
<p>            pool.errorQueue <- fmt.Errorf("worker %d panicked: %v", workerID, r)</p>
<p>        }</p>
<p>    }()</p>
    
<p>    // Process the task using existing controller logic</p>
<p>    err := pool.controller.ProcessSingleTask(task)</p>
    
<p>    return TaskResult{</p>
<p>        TaskSeq:  task.TaskSeq,</p>
<p>        Success:  err == nil,</p>
<p>        Error:    err,</p>
<p>        Duration: time.Since(startTime),</p>
<p>    }</p>
<p>}</p>
<p>func (pool </em>TaskWorkerPool) SubmitTask(task executionModels.PlayBookTask) {</p>
<p>    select {</p>
<p>    case pool.taskQueue <- task:</p>
<p>        // Task submitted successfully</p>
<p>    case <-time.After(5 <em> time.Second):</p>
<p>        logger.Error("Task submission timeout", "task_seq", task.TaskSeq)</p>
<p>    }</p>
<p>}</p>
<p>func (pool </em>TaskWorkerPool) Stop() {</p>
<p>    close(pool.stopSignal)</p>
<p>    pool.wg.Wait()</p>
<p>    close(pool.taskQueue)</p>
<p>    close(pool.resultQueue)</p>
<p>    close(pool.errorQueue)</p>
<p>}</p>
<p>func (pool <em>TaskWorkerPool) GetResults() <-chan TaskResult {</p>
<p>    return pool.resultQueue</p>
<p>}</p>
<p>func (pool </em>TaskWorkerPool) GetErrors() <-chan error {</p>
<p>    return pool.errorQueue</p>
<p>}</code></pre></p>
<h3><strong>3.2 Parallel Execution in PlaybookExecutionController</strong></h3>
<strong>File</strong>: <code>executionControllers/playbookExecutionController.go</code>
<p>Add this method to the PlaybookExecutionController struct:</p>
<pre><code class="language-go">// Add this method to PlaybookExecutionController
<p>func (executionController <em>PlaybookExecutionController) ExecuteTasksInParallel(</p>
<p>    tasks []executionModels.PlayBookTask,</p>
<p>    maxWorkers int,</p>
<p>) error {</p>
    
<p>    if len(tasks) == 0 {</p>
<p>        return nil</p>
<p>    }</p>
    
<p>    // Determine optimal number of workers</p>
<p>    workerCount := maxWorkers</p>
<p>    if len(tasks) < maxWorkers {</p>
<p>        workerCount = len(tasks)</p>
<p>    }</p>
    
<p>    // Create worker pool</p>
<p>    pool := NewTaskWorkerPool(workerCount, len(tasks), executionController)</p>
<p>    pool.Start()</p>
<p>    defer pool.Stop()</p>
    
<p>    // Submit all tasks</p>
<p>    for _, task := range tasks {</p>
<p>        pool.SubmitTask(task)</p>
<p>    }</p>
    
<p>    // Collect results</p>
<p>    var errors []error</p>
<p>    resultsCollected := 0</p>
    
<p>    for resultsCollected < len(tasks) {</p>
<p>        select {</p>
<p>        case result := <-pool.GetResults():</p>
<p>            resultsCollected++</p>
<p>            if !result.Success {</p>
<p>                errors = append(errors, result.Error)</p>
<p>            }</p>
<p>            logger.Info("Task completed", </p>
<p>                "task_seq", result.TaskSeq,</p>
<p>                "success", result.Success,</p>
<p>                "duration", result.Duration,</p>
<p>            )</p>
            
<p>        case err := <-pool.GetErrors():</p>
<p>            errors = append(errors, err)</p>
<p>            resultsCollected++</p>
            
<p>        case <-time.After(30 </em> time.Second):</p>
<p>            return fmt.Errorf("timeout waiting for task results")</p>
<p>        }</p>
<p>    }</p>
    
<p>    // Return first error if any</p>
<p>    if len(errors) > 0 {</p>
<p>        return errors[0]</p>
<p>    }</p>
    
<p>    return nil</p>
<p>}</p>
<p>// Usage in existing execution flow:</p>
<p>func (executionController <em>PlaybookExecutionController) ProcessAndExecuteTasksParallel() error {</p>
<p>    // Get tasks that can be executed in parallel</p>
<p>    parallelTasks := executionController.getParallelExecutableTasks()</p>
    
<p>    if len(parallelTasks) > 1 {</p>
<p>        // Execute in parallel</p>
<p>        return executionController.ExecuteTasksInParallel(parallelTasks, 10)</p>
<p>    } else {</p>
<p>        // Execute sequentially for single task or dependent tasks</p>
<p>        return executionController.executeTasksSequentially(parallelTasks)</p>
<p>    }</p>
<p>}</code></pre></p>
<p>---</p>
<h2>üìã <strong>Priority 4: Caching Strategy Implementation (Week 3-4)</strong></h2>
<h3><strong>4.1 Multi-Level Cache Manager</strong></h3>
<strong>File</strong>: Create new <code>cache/multiLevelCache.go</code>
<pre><code class="language-go">package cache
<p>import (</p>
<p>    "encoding/json"</p>
<p>    "sync"</p>
<p>    "time"</p>
<p>    "github.com/go-redis/redis/v8"</p>
<p>)</p>
<p>type MultiLevelCacheManager struct {</p>
<p>    l1Cache     </em>sync.Map                 // In-memory L1 cache</p>
<p>    l2Cache     <em>redis.Client             // Redis L2 cache</p>
<p>    ttlMap      </em>sync.Map                 // TTL tracking for L1</p>
<p>    cleanupStop chan struct{}</p>
<p>    mutex       sync.RWMutex</p>
<p>}</p>
<p>type CacheItem struct {</p>
<p>    Value     interface{}</p>
<p>    ExpiresAt int64</p>
<p>}</p>
<p>func NewMultiLevelCacheManager(redisClient <em>redis.Client) </em>MultiLevelCacheManager {</p>
<p>    manager := &MultiLevelCacheManager{</p>
<p>        l1Cache:     &sync.Map{},</p>
<p>        l2Cache:     redisClient,</p>
<p>        ttlMap:      &sync.Map{},</p>
<p>        cleanupStop: make(chan struct{}),</p>
<p>    }</p>
    
<p>    // Start cleanup goroutine</p>
<p>    go manager.startCleanupRoutine()</p>
    
<p>    return manager</p>
<p>}</p>
<p>func (cm <em>MultiLevelCacheManager) Get(key string) (interface{}, bool) {</p>
<p>    cm.mutex.RLock()</p>
<p>    defer cm.mutex.RUnlock()</p>
    
<p>    // Check L1 cache first</p>
<p>    if item, exists := cm.l1Cache.Load(key); exists {</p>
<p>        cacheItem := item.(CacheItem)</p>
<p>        if time.Now().Unix() < cacheItem.ExpiresAt {</p>
<p>            return cacheItem.Value, true</p>
<p>        } else {</p>
<p>            // Expired, remove from L1</p>
<p>            cm.l1Cache.Delete(key)</p>
<p>        }</p>
<p>    }</p>
    
<p>    // Fall back to L2 cache (Redis)</p>
<p>    result, err := cm.l2Cache.Get(context.Background(), key).Result()</p>
<p>    if err == nil {</p>
<p>        var value interface{}</p>
<p>        if err := json.Unmarshal([]byte(result), &value); err == nil {</p>
<p>            // Promote to L1 cache with shorter TTL</p>
<p>            cm.setL1Cache(key, value, 5</em>time.Minute)</p>
<p>            return value, true</p>
<p>        }</p>
<p>    }</p>
    
<p>    return nil, false</p>
<p>}</p>
<p>func (cm <em>MultiLevelCacheManager) Set(key string, value interface{}, ttl time.Duration) error {</p>
<p>    cm.mutex.Lock()</p>
<p>    defer cm.mutex.Unlock()</p>
    
<p>    // Store in L1 cache</p>
<p>    cm.setL1Cache(key, value, ttl)</p>
    
<p>    // Store in L2 cache (Redis)</p>
<p>    data, err := json.Marshal(value)</p>
<p>    if err != nil {</p>
<p>        return err</p>
<p>    }</p>
    
<p>    return cm.l2Cache.Set(context.Background(), key, data, ttl).Err()</p>
<p>}</p>
<p>func (cm </em>MultiLevelCacheManager) setL1Cache(key string, value interface{}, ttl time.Duration) {</p>
<p>    expiresAt := time.Now().Add(ttl).Unix()</p>
<p>    cm.l1Cache.Store(key, CacheItem{</p>
<p>        Value:     value,</p>
<p>        ExpiresAt: expiresAt,</p>
<p>    })</p>
<p>}</p>
<p>func (cm <em>MultiLevelCacheManager) Delete(key string) {</p>
<p>    cm.l1Cache.Delete(key)</p>
<p>    cm.l2Cache.Del(context.Background(), key)</p>
<p>}</p>
<p>func (cm </em>MultiLevelCacheManager) startCleanupRoutine() {</p>
<p>    ticker := time.NewTicker(5 <em> time.Minute)</p>
<p>    defer ticker.Stop()</p>
    
<p>    for {</p>
<p>        select {</p>
<p>        case <-ticker.C:</p>
<p>            cm.cleanupExpiredL1Items()</p>
<p>        case <-cm.cleanupStop:</p>
<p>            return</p>
<p>        }</p>
<p>    }</p>
<p>}</p>
<p>func (cm </em>MultiLevelCacheManager) cleanupExpiredL1Items() {</p>
<p>    now := time.Now().Unix()</p>
<p>    cm.l1Cache.Range(func(key, value interface{}) bool {</p>
<p>        item := value.(CacheItem)</p>
<p>        if now >= item.ExpiresAt {</p>
<p>            cm.l1Cache.Delete(key)</p>
<p>        }</p>
<p>        return true</p>
<p>    })</p>
<p>}</p>
<p>func (cm <em>MultiLevelCacheManager) Stop() {</p>
<p>    close(cm.cleanupStop)</p>
<p>}</code></pre></p>
<h3><strong>4.2 Cache Integration in Controllers</strong></h3>
<strong>File</strong>: Modify <code>controllers/playbookcontroller.go</code>
<pre><code class="language-go">// Add caching to playbook operations
<p>var cacheManager </em>cache.MultiLevelCacheManager</p>
<p>func init() {</p>
<p>    redisClient := cache.GetOptimizedRedisClient()</p>
<p>    cacheManager = cache.NewMultiLevelCacheManager(redisClient)</p>
<p>}</p>
<p>// Modify GetPlaybookByName function to use cache</p>
<p>func (pc PlaybookController) GetPlaybookByName(tenantCode, playbookName string) (<em>models.PlaybookObject, error) {</p>
<p>    cacheKey := fmt.Sprintf("playbook:%s:%s", tenantCode, playbookName)</p>
    
<p>    // Try cache first</p>
<p>    if cached, exists := cacheManager.Get(cacheKey); exists {</p>
<p>        if playbook, ok := cached.(</em>models.PlaybookObject); ok {</p>
<p>            logger.Debug("Playbook retrieved from cache", "key", cacheKey)</p>
<p>            return playbook, nil</p>
<p>        }</p>
<p>    }</p>
    
<p>    // Cache miss - get from database</p>
<p>    playbook, err := pc.getPlaybookFromDatabase(tenantCode, playbookName)</p>
<p>    if err != nil {</p>
<p>        return nil, err</p>
<p>    }</p>
    
<p>    // Store in cache for 1 hour</p>
<p>    cacheManager.Set(cacheKey, playbook, 1<em>time.Hour)</p>
<p>    logger.Debug("Playbook stored in cache", "key", cacheKey)</p>
    
<p>    return playbook, nil</p>
<p>}</p>
<p>// Cache invalidation when playbook is updated</p>
<p>func (pc PlaybookController) UpdatePlaybook(playbook </em>models.PlaybookObject) error {</p>
<p>    err := pc.updatePlaybookInDatabase(playbook)</p>
<p>    if err != nil {</p>
<p>        return err</p>
<p>    }</p>
    
<p>    // Invalidate cache</p>
<p>    cacheKey := fmt.Sprintf("playbook:%s:%s", playbook.TenantCode, playbook.Name)</p>
<p>    cacheManager.Delete(cacheKey)</p>
    
<p>    return nil</p>
<p>}</code></pre></p>
<p>---</p>
<h2>üìã <strong>Priority 5: Memory Management Optimizations (Week 4)</strong></h2>
<h3><strong>5.1 Object Pooling Implementation</strong></h3>
<strong>File</strong>: Create new <code>utils/objectPool.go</code>
<pre><code class="language-go">package utils
<p>import (</p>
<p>    "sync"</p>
<p>    "securaa_services/securaa_playbook/models"</p>
<p>)</p>
<p>// Object pools for frequently allocated objects</p>
<p>var (</p>
<p>    taskRequestPool = sync.Pool{</p>
<p>        New: func() interface{} {</p>
<p>            return &models.TaskRequest{}</p>
<p>        },</p>
<p>    }</p>
    
<p>    playbookObjectPool = sync.Pool{</p>
<p>        New: func() interface{} {</p>
<p>            return &models.PlaybookObject{}</p>
<p>        },</p>
<p>    }</p>
    
<p>    responsePool = sync.Pool{</p>
<p>        New: func() interface{} {</p>
<p>            return &models.Response{}</p>
<p>        },</p>
<p>    }</p>
    
<p>    stringBuilderPool = sync.Pool{</p>
<p>        New: func() interface{} {</p>
<p>            return &strings.Builder{}</p>
<p>        },</p>
<p>    }</p>
<p>)</p>
<p>// TaskRequest pool functions</p>
<p>func GetTaskRequest() <em>models.TaskRequest {</p>
<p>    req := taskRequestPool.Get().(</em>models.TaskRequest)</p>
<p>    // Reset the object</p>
<p>    <em>req = models.TaskRequest{}</p>
<p>    return req</p>
<p>}</p>
<p>func PutTaskRequest(req </em>models.TaskRequest) {</p>
<p>    taskRequestPool.Put(req)</p>
<p>}</p>
<p>// PlaybookObject pool functions</p>
<p>func GetPlaybookObject() <em>models.PlaybookObject {</p>
<p>    pb := playbookObjectPool.Get().(</em>models.PlaybookObject)</p>
<p>    // Reset the object</p>
<p>    <em>pb = models.PlaybookObject{}</p>
<p>    return pb</p>
<p>}</p>
<p>func PutPlaybookObject(pb </em>models.PlaybookObject) {</p>
<p>    playbookObjectPool.Put(pb)</p>
<p>}</p>
<p>// Response pool functions</p>
<p>func GetResponse() <em>models.Response {</p>
<p>    resp := responsePool.Get().(</em>models.Response)</p>
<p>    // Reset the object</p>
<p>    <em>resp = models.Response{}</p>
<p>    return resp</p>
<p>}</p>
<p>func PutResponse(resp </em>models.Response) {</p>
<p>    responsePool.Put(resp)</p>
<p>}</p>
<p>// StringBuilder pool functions</p>
<p>func GetStringBuilder() <em>strings.Builder {</p>
<p>    sb := stringBuilderPool.Get().(</em>strings.Builder)</p>
<p>    sb.Reset()</p>
<p>    return sb</p>
<p>}</p>
<p>func PutStringBuilder(sb <em>strings.Builder) {</p>
<p>    stringBuilderPool.Put(sb)</p>
<p>}</p>
<p>// Usage example in JSON response building</p>
<p>func BuildJSONResponse(status string, message string, data interface{}) string {</p>
<p>    sb := GetStringBuilder()</p>
<p>    defer PutStringBuilder(sb)</p>
    
<p>    sb.WriteString(<code>{"status":"</code>)</p>
<p>    sb.WriteString(status)</p>
<p>    sb.WriteString(<code>","message":"</code>)</p>
<p>    sb.WriteString(message)</p>
<p>    sb.WriteString(<code>","data":</code>)</p>
    
<p>    if dataBytes, err := json.Marshal(data); err == nil {</p>
<p>        sb.Write(dataBytes)</p>
<p>    } else {</p>
<p>        sb.WriteString("null")</p>
<p>    }</p>
    
<p>    sb.WriteString("}")</p>
<p>    return sb.String()</p>
<p>}</code></pre></p>
<h3><strong>5.2 Memory-Optimized JSON Processing</strong></h3>
<strong>File</strong>: Create new <code>utils/jsonOptimizer.go</code>
<pre><code class="language-go">package utils
<p>import (</p>
<p>    "encoding/json"</p>
<p>    "io"</p>
<p>    "bytes"</p>
<p>)</p>
<p>// StreamingJSONProcessor for large JSON data</p>
<p>type StreamingJSONProcessor struct {</p>
<p>    decoder </em>json.Decoder</p>
<p>    buffer  <em>bytes.Buffer</p>
<p>}</p>
<p>func NewStreamingJSONProcessor(reader io.Reader) </em>StreamingJSONProcessor {</p>
<p>    return &StreamingJSONProcessor{</p>
<p>        decoder: json.NewDecoder(reader),</p>
<p>        buffer:  &bytes.Buffer{},</p>
<p>    }</p>
<p>}</p>
<p>func (processor <em>StreamingJSONProcessor) ProcessLargeJSON(callback func(interface{}) error) error {</p>
<p>    for processor.decoder.More() {</p>
<p>        var item interface{}</p>
<p>        if err := processor.decoder.Decode(&item); err != nil {</p>
<p>            return err</p>
<p>        }</p>
        
<p>        if err := callback(item); err != nil {</p>
<p>            return err</p>
<p>        }</p>
<p>    }</p>
<p>    return nil</p>
<p>}</p>
<p>// Optimized JSON marshaling with buffer reuse</p>
<p>func MarshalJSONOptimized(v interface{}) ([]byte, error) {</p>
<p>    buffer := GetStringBuilder()</p>
<p>    defer PutStringBuilder(buffer)</p>
    
<p>    encoder := json.NewEncoder(buffer)</p>
<p>    encoder.SetEscapeHTML(false) // Faster encoding</p>
    
<p>    if err := encoder.Encode(v); err != nil {</p>
<p>        return nil, err</p>
<p>    }</p>
    
<p>    // Remove trailing newline added by Encode</p>
<p>    result := buffer.String()</p>
<p>    if len(result) > 0 && result[len(result)-1] == '\n' {</p>
<p>        result = result[:len(result)-1]</p>
<p>    }</p>
    
<p>    return []byte(result), nil</p>
<p>}</p>
<p>// Schema validation with caching</p>
<p>var schemaCache = sync.Map{}</p>
<p>func ValidateJSONWithCachedSchema(data []byte, schemaName string) error {</p>
<p>    if schema, exists := schemaCache.Load(schemaName); exists {</p>
<p>        return validateWithSchema(data, schema)</p>
<p>    }</p>
    
<p>    schema, err := loadSchema(schemaName)</p>
<p>    if err != nil {</p>
<p>        return err</p>
<p>    }</p>
    
<p>    schemaCache.Store(schemaName, schema)</p>
<p>    return validateWithSchema(data, schema)</p>
<p>}</code></pre></p>
<p>---</p>
<h2>üìã <strong>Implementation Timeline & Testing Strategy</strong></h2>
<h3><strong>Week 1: Database & Connection Optimizations</strong></h3>
<pre><code class="language-bash"><h1>Day 1-2: Database indexes</h1>
<ul>
<li>Create index scripts</li>
<li>Test query performance before/after</li>
<li>Monitor slow query logs</li>
</ul>
<h1>Day 3-5: Connection pool optimization</h1>
<ul>
<li>Implement MongoDB connection pooling</li>
<li>Configure Redis connection optimization</li>
<li>Load test with concurrent requests</code></pre></li>
</ul>
<h3><strong>Week 2: Parallel Processing Foundation</strong></h3>
<pre><code class="language-bash"><h1>Day 1-3: Worker pool implementation</h1>
<ul>
<li>Create worker pool structure</li>
<li>Test with sample tasks</li>
<li>Benchmark sequential vs parallel</li>
</ul>
<h1>Day 4-5: Integration with execution controller</h1>
<ul>
<li>Modify existing execution flow</li>
<li>Test parallel task execution</li>
<li>Monitor resource usage</code></pre></li>
</ul>
<h3><strong>Week 3: Caching & Memory Management</strong></h3>
<pre><code class="language-bash"><h1>Day 1-3: Multi-level cache implementation</h1>
<ul>
<li>Implement cache manager</li>
<li>Integrate with controllers</li>
<li>Test cache hit/miss ratios</li>
</ul>
<h1>Day 4-5: Object pooling</h1>
<ul>
<li>Implement object pools</li>
<li>Integrate with request processing</li>
<li>Memory profiling and optimization</code></pre></li>
</ul>
<h3><strong>Week 4: Performance Testing & Monitoring</strong></h3>
<pre><code class="language-bash"><h1>Day 1-3: Load testing</h1>
<ul>
<li>Create load test scenarios</li>
<li>Test optimized vs original code</li>
<li>Measure performance improvements</li>
</ul>
<h1>Day 4-5: Monitoring implementation</h1>
<ul>
<li>Add performance metrics</li>
<li>Create dashboards</li>
<li>Set up alerting</code></pre></li>
</ul>
<p>---</p>
<h2>üìä <strong>Performance Benchmarking Commands</strong></h2>
<h3><strong>Database Performance Testing</strong></h3>
<pre><code class="language-bash"><h1>Before optimization</h1>
<p>go test -bench=BenchmarkQueryPlaybooks -count=5 -benchmem</p>
<h1>After optimization (should show 5-10x improvement)</h1>
<p>go test -bench=BenchmarkQueryPlaybooksOptimized -count=5 -benchmem</code></pre></p>
<h3><strong>Concurrency Testing</strong></h3>
<pre><code class="language-bash"><h1>Test parallel execution</h1>
<p>go test -bench=BenchmarkParallelExecution -count=5 -benchmem</p>
<h1>Load testing with hey tool</h1>
<p>hey -n 1000 -c 50 -m POST -d '{"playbook_name":"test"}' \</p>
<p>    http://localhost:8040/runplaybook/</code></pre></p>
<h3><strong>Memory Profiling</strong></h3>
<pre><code class="language-bash"><h1>Enable pprof in main.go</h1>
<p>import _ "net/http/pprof"</p>
<h1>Memory profiling</h1>
<p>go tool pprof http://localhost:6060/debug/pprof/heap</p>
<h1>CPU profiling during load test</h1>
<p>go tool pprof http://localhost:6060/debug/pprof/profile?seconds=30</code></pre></p>
<p>---</p>
<h2>üîç <strong>Monitoring & Metrics</strong></h2>
<h3><strong>Key Performance Indicators to Track</strong></h3>
<pre><code class="language-go">// Add these metrics to your monitoring
<p>type PerformanceMetrics struct {</p>
<p>    DatabaseQueryTime     time.Duration</p>
<p>    CacheHitRatio        float64</p>
<p>    ConcurrentExecutions int</p>
<p>    MemoryUsage          int64</p>
<p>    TaskThroughput       int</p>
<p>    ErrorRate            float64</p>
<p>}</p>
<p>// Example metrics collection</p>
<p>func collectMetrics() {</p>
<p>    // Database query time</p>
<p>    start := time.Now()</p>
<p>    // ... database query</p>
<p>    dbQueryTime := time.Since(start)</p>
    
<p>    // Cache metrics</p>
<p>    cacheHits := getCacheHits()</p>
<p>    cacheMisses := getCacheMisses()</p>
<p>    hitRatio := float64(cacheHits) / float64(cacheHits + cacheMisses)</p>
    
<p>    // Memory usage</p>
<p>    var m runtime.MemStats</p>
<p>    runtime.ReadMemStats(&m)</p>
<p>    memoryUsage := int64(m.Alloc)</p>
    
<p>    // Log metrics</p>
<p>    logger.Info("Performance metrics",</p>
<p>        "db_query_time", dbQueryTime,</p>
<p>        "cache_hit_ratio", hitRatio,</p>
<p>        "memory_usage_mb", memoryUsage/1024/1024,</p>
<p>    )</p>
<p>}</code></pre></p>
<p>---</p>
<h2>‚ö†Ô∏è <strong>Implementation Notes & Warnings</strong></h2>
<h3><strong>Database Optimizations</strong></h3>
<ul>
<li><strong>Index Creation</strong>: Run during maintenance window, can be resource intensive</li>
<li><strong>Connection Pools</strong>: Monitor connection usage, adjust pool sizes based on load</li>
<li><strong>Batch Operations</strong>: Test batch sizes, larger isn't always better</li>
</ul>
<h3><strong>Concurrency Optimizations</strong></h3>
<ul>
<li><strong>Worker Pool Size</strong>: Start with CPU count </em> 2, adjust based on I/O vs CPU bound tasks</li>
<li><strong>Channel Buffer Sizes</strong>: Balance memory usage vs throughput</li>
<li><strong>Context Cancellation</strong>: Always implement proper cancellation to prevent goroutine leaks</li>
</ul>
<h3><strong>Memory Management</strong></h3>
<ul>
<li><strong>Object Pools</strong>: Only beneficial for frequently allocated objects</li>
<li><strong>Cache Sizes</strong>: Monitor memory usage, implement cache eviction policies</li>
<li><strong>Garbage Collection</strong>: Profile GC pressure, adjust GOGC if needed</li>
</ul>
<h3><strong>Testing Requirements</strong></h3>
<ul>
<li><strong>Load Testing</strong>: Test with production-like data volumes</li>
<li><strong>Race Condition Testing</strong>: Use <code>go test -race</code> for all concurrent code</li>
<li><strong>Memory Leak Testing</strong>: Run long-duration tests with memory monitoring</li>
</ul>
<hr>
<h2>üìà <strong>Expected Performance Improvements</strong></h2>
<table>
    <thead>
        <tr>
            <th>Optimization</th>
            <th>Metric</th>
            <th>Current</th>
            <th>Optimized</th>
            <th>Improvement</th>
        </tr>
    </thead>
    <tbody>
        <tr>
            <td>Database Queries</td>
            <td>Response Time</td>
            <td>500-2000ms</td>
            <td>50-200ms</td>
            <td><strong>5-10x faster</strong></td>
        </tr>
        <tr>
            <td>Concurrent Requests</td>
            <td>Throughput</td>
            <td>100 req/sec</td>
            <td>300-400 req/sec</td>
            <td><strong>3-4x increase</strong></td>
        </tr>
        <tr>
            <td>Memory Usage</td>
            <td>Heap Allocation</td>
            <td>100MB</td>
            <td>30-50MB</td>
            <td><strong>50-70% reduction</strong></td>
        </tr>
        <tr>
            <td>Task Execution</td>
            <td>Parallel Tasks</td>
            <td>Sequential</td>
            <td>5-10 parallel</td>
            <td><strong>5-10x throughput</strong></td>
        </tr>
        <tr>
            <td>Cache Hit Ratio</td>
            <td>Cache Performance</td>
            <td>0%</td>
            <td>80-90%</td>
            <td><strong>80-90% cache hits</strong></td>
        </tr>
    </tbody>
</table>
<hr>
<h2>üöÄ <strong>Getting Started Checklist</strong></h2>
<ul>
<li>[ ] <strong>Week 1</strong>: Create database indexes and test query performance</li>
<li>[ ] <strong>Week 1</strong>: Implement connection pool optimizations</li>
<li>[ ] <strong>Week 2</strong>: Create worker pool for parallel task execution</li>
<li>[ ] <strong>Week 2</strong>: Integrate parallel processing with existing controllers</li>
<li>[ ] <strong>Week 3</strong>: Implement multi-level caching strategy</li>
<li>[ ] <strong>Week 3</strong>: Add object pooling for memory optimization</li>
<li>[ ] <strong>Week 4</strong>: Comprehensive load testing and performance validation</li>
<li>[ ] <strong>Week 4</strong>: Set up monitoring and alerting for optimized metrics</li>
</ul>
<p>---</p>
<strong>Questions or need clarification on any optimization? Contact the development team lead or create an issue in the project repository.</strong>

    </main>
    
    <footer class="main-footer">
        <p>&copy; 2025 Securaa Platform. All rights reserved.</p>
    </footer>
    
    <script src="https://cdn.jsdelivr.net/npm/mermaid@10.9.4/dist/mermaid.min.js"></script>
    <script>
        mermaid.initialize({ 
            startOnLoad: true,
            theme: 'default',
            themeVariables: {
                primaryColor: '#1976d2',
                primaryTextColor: '#000000',
                primaryBorderColor: '#0d47a1',
                lineColor: '#1976d2',
                secondaryColor: '#f5f5f5',
                tertiaryColor: '#ffffff'
            }
        });
    </script>
    <script src="assets/js/documentation.js"></script>
</body>
</html>